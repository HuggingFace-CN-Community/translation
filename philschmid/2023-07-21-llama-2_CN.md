# LLaMA 2 - 你所需要的一切资源

## 摘录

> 关于 LLaMA 2 的全部资源，如何去测试、训练并部署它。

---

LLaMA 2 是一个由 Meta 开发的大型语言模型，是 LLaMA 1 的继任者。LLaMA 2 可通过 AWS、Hugging Face 等提供商获取，并免费用于研究和商业用途。LLaMA 2 预训练模型在 2 万亿个标记上进行训练，相比 LLaMA 1 的上下文长度增加了一倍。它的微调模型则在超过 100 万个人工标注数据下完成。

这篇博客包含了所有的相关资源，以帮助您快速入门。包括以下跳转:

- [LLaMA 2 是什么？](https://www.philschmid.de/llama-2#what-is-llama-2)
- [在 LLaMA 游乐场试玩](https://www.philschmid.de/llama-2#llama-playgrounds-test-it)
- [模型背后的研究工作](https://www.philschmid.de/llama-2#research-behind-llama-2)
- [模型的性能有多好，基准测试](https://www.philschmid.de/llama-2#how-good-is-llama-2-benchmarks)
- [如何正确地去提示聊天模型](https://www.philschmid.de/llama-2#how-to-prompt-llama-2-chat)
- [如何使用 PEFT 训练模型](https://www.philschmid.de/llama-2#how-to-train-llama-2)
- [如何部署模型进行推理](https://www.philschmid.de/llama-2#how-to-deploy-llama-2)
- [和其他资源](https://www.philschmid.de/llama-2#other-sources)

来自 Meta 官方的公告可以在这里找到: [https://ai.meta.com/llama/](https://ai.meta.com/llama/)

## LLaMA 2 是什么？

Meta 发布的 LLaMA 2，是新的 sota 开源大型语言模型 (LLM)。LLaMA 2 代表着 LLaMA 的下一代版本，并且具有商业许可证。LLaMA 2 有 3 种不同的大小——7B、13B 和 70B 个可训练参数。与原版 LLaMA 相比，新的改进包括:

- 在 2 万亿个标记的文本数据上进行训练
- 允许商业使用
- 默认使用 4096 个前后文本视野 ([可以被扩展](https://twitter.com/joao_gante/status/1681593605541236736?s=20))
- 70B 模型采用了分组查询注意力 (GQA)
- 可由此获取 [Hugging Face Hub](https://huggingface.co/models?other=llama-2)

## 在 LLaMA 游乐场试玩

有几个不同的游乐场供与 LLaMA 2 来测试聊天:

- [HuggingChat](https://huggingface.co/chat) 允许你通过 Hugging Face 的对话界面与 LLaMA 2 70B 模型聊天。这提供了一个简洁的方法来了解聊天机器人的工作原理。
- [Hugging Face Spaces](https://huggingface.co/spaces) 有三种大小的 LLaMA 2 模型 [7B](https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat)、[13B](https://huggingface.co/spaces/huggingface-projects/llama-2-13b-chat) 和 [70B](https://huggingface.co/spaces/ysharma/Explore_llamav2_with_TGI) 可供测试。交互式演示可以让您比较不同的大小模型的区别。
- [Perplexity](https://llama.perplexity.ai/) 他们的对话 AI 演示提供 7B 和 13B 的 LLaMA 2 模型。你可以与模型聊天并且反馈模型响应的不足。

## LLaMA 2 背后的研究工作

LLaMA 2 是一个基础大语言模型，它由网络上公开可获取到的数据训练完成。另外 Meta 同时发布了它的 CHAT 版本。CHAT 模型的第一个版本是 SFT (有监督调优) 模型。在这之后，LLaMA-2-chat 逐步地经过人类反馈强化学习 (RLHF) 来进化。 RLHF 的过程使用了拒绝采样与近端策略优化 (PPO) 的技术来进一步调优聊天机器人。 Meta 目前仅公布了模型最新的 RLHF(v5) 版本。若你对此过程背后的过程感兴趣则请查看:

- [Llama 2: 开源并已微调的聊天模型](https://arxiv.org/abs/2307.09288)
- [Llama 2: 一个超赞的开源大语言模型](https://www.interconnects.ai/p/llama-2-from-meta)
- [Llama 2: 全面拆解](https://www.youtube.com/watch?v=zJBpRn2zTco&ab_channel=AIExplained)

## LLaMA 2 的性能有多好，基准测试？

Meta 声称 _“Llama 2 在众多外部基准测试中都优于其他开源的语言模型，包括推理、编程、熟练程度与知识测验”_ 关于其性能你可以在这里找到更多信息:

- [Hugging Face 开源大语言模型排行榜](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
- [Meta 官方公告](https://ai.meta.com/llama/)

## 如何提示 LLaMA 2 Chat

LLaMA 2 Chat 是一个开源对话模型。想要与 LLaMA 2 Chat 进行高效地交互则需要你提供合适的提示词、问题来得到合乎逻辑且有帮助的回复。 Meta 并没有选择最简单的提示词结构。以下是单轮、多轮对话的提示词模板。这个模板遵循模型的训练过程，在此详细描述 [LLaMA 2 论文](https://huggingface.co/papers/2307.09288). 你也可以看一看 [LLaMA 2 提示词模板](https://gpus.llm-utils.org/llama-2-prompt-template/).

单轮对话

```
<s>[INST] <<SYS>>
{{ system_prompt }}
<</SYS>>
{{ user_message }} [/INST]
```

多轮对话

```
<s>[INST] <<SYS>>
{{ system_prompt }}
<</SYS>>
{{ user_msg_1 }} [/INST]{{ model_answer_1 }} </s><s>[INST]{{ user_msg_2 }} [/INST]{{ model_answer_2 }} </s><s>[INST]{{ user_msg_3 }} [/INST]
```

## 如何训练 LLaMA 2

因 LLaMA 2 为开源模型，使得可以轻易的通过微调技术，比如 PEFT，来训练它。这是一些非日适合于训练你自己版本 LLaMA 2 的学习资源:

- [扩展指引: 指令微调 Llama 2](https://www.philschmid.de/instruction-tune-llama-2)
- [在 Amazon SageMaker 上微调 LLaMA 2 (7-70B)](https://www.philschmid.de/sagemaker-llama2-qlora)
- [使用 PEFT 技术微调](https://huggingface.co/blog/llama2#fine-tuning-with-peft)
- [Meta 提供的 Llama 模型示例以及方案](https://github.com/facebookresearch/llama-recipes/tree/main)
- [在本地机器上微调 LLAMA-v2 最简单的方法 !](https://www.youtube.com/watch?v=3fsn19OI_C8&ab_channel=AbhishekThakur)

## 如何部属 LLaMA 2

LLaMA 2 可以在本地环境中部署 ([llama.cpp](https://github.com/ggerganov/llama.cpp))，使用这样已管理好的服务 [Hugging Face Inference Endpoints](https://ui.endpoints.huggingface.co/) 或通过 AWS, Google Cloud, and Microsoft Azure 这样的服务器平台.

- [使用文本生成接口与推理终端来部署 LLama 2](https://huggingface.co/blog/llama2#using-text-generation-inference-and-inference-endpoints)
- 使用 Amazon SageMaker 部署 LLaMA 2 70B (即将完成)
- [在你的 M1/M2 Mac 上通过 GPU 接口来本地部署 Llama-2-13B-chat](https://gist.github.com/adrienbrault/b76631c56c736def9bc1bc2167b5d129)

## 其他资源

- [Llama 2 资源](https://gpus.llm-utils.org/llama-2-resources/)

如果你想让我再增添一些章节或其他细节请联系我。我致力于提供基于 LLaMA 2 目前已公开信息的高质量概述。