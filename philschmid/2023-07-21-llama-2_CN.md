# LLaMA 2 - 你所需要的一切资源

> ## 摘录
> 关于LLaMA 2的全部资源，如何去测试，训练，并部署它。

---
LLaMA 2是一个由Meta开发的大型语言模型，是LLaMA 1的继任者。LLaMA 2可通过AWS、Hugging Face等提供商获取，并免费用于研究和商业用途。LLaMA 2预训练模型在2万亿个标记上进行训练，相比LLaMA 1的上下文长度增加了一倍。它的微调模型则在超过100万个人工标注数据下完成。

这篇博客包含了所有的相关资源，以帮助您快速入门。包括以下跳转：

-   [LLaMA 2是什么？](https://www.philschmid.de/llama-2#what-is-llama-2)
-   [游乐场，你可以在这里测试模型](https://www.philschmid.de/llama-2#llama-playgrounds-test-it)
-   [模型背后的研究工作](https://www.philschmid.de/llama-2#research-behind-llama-2)
-   [模型的性能有多好，基准测试](https://www.philschmid.de/llama-2#how-good-is-llama-2-benchmarks)
-   [如何正确地去提示聊天模型](https://www.philschmid.de/llama-2#how-to-prompt-llama-2-chat)
-   [如何使用PEFT训练模型](https://www.philschmid.de/llama-2#how-to-train-llama-2)
-   [如何部署模型进行推理](https://www.philschmid.de/llama-2#how-to-deploy-llama-2)
-   [和其他资源](https://www.philschmid.de/llama-2#other-sources)


来自Meta官方的公告可以在这里找到：[https://ai.meta.com/llama/](https://ai.meta.com/llama/)

## LLaMA 2是什么？

Meta发布的LLaMA 2，是新的sota开源大型语言模型（LLM）。LLaMA 2代表着LLaMA的下一代版本，并且具有商业许可证。LLaMA 2有3种不同的大小——7B、13B和70B个可训练参数。与原版LLaMA相比，新的改进包括：

-   在2万亿个标记的文本数据上进行训练
-   允许商业使用
-   默认使用4096个前后文本视野（[可以被扩展](https://twitter.com/joao_gante/status/1681593605541236736?s=20)）
-   70B模型采用了分组查询注意力（GQA）
-   可由此获取[Hugging Face Hub](https://huggingface.co/models?other=llama-2)

## 在LLaMA 游乐场，测试它

有几个不同的游乐场供与LLaMA 2来测试聊天：

-   [HuggingChat](https://huggingface.co/chat) 允许你通过Hugging Face的对话界面与LLaMA 2 70B模型聊天。这提供了一个简洁的方法来了解聊天机器人的工作原理。
-   [Hugging Face Spaces](https://huggingface.co/spaces) 有三种大小的LLaMA 2模型[7B](https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat)、[13B](https://huggingface.co/spaces/huggingface-projects/llama-2-13b-chat)和[70B](https://huggingface.co/spaces/ysharma/Explore_llamav2_with_TGI)可供测试。交互式演示可以让您比较不同的大小模型的区别。
-   [Perplexity](https://llama.perplexity.ai/) 他们的对话AI演示提供7B和13B的LLaMA 2模型。你可以与模型聊天并且反馈模型响应的不足。

## LLaMA 2背后的研究工作

LLaMA 2是一个基础大语言模型，它由网络上公开可获取到的数据训练完成。另外Meta同时发布了它的CHAT版本。CHAT模型的第一个版本是SFT（有监督调优）模型。在这之后，LLaMA-2-chat逐步地经过人类反馈强化学习（RLHF）来进化。 RLHF的过程使用了拒绝采样与近端策略优化（PPO）的技术来进一步调优聊天机器人。 Meta目前仅公布了模型最新的RLHF(v5)版本。若你对此过程背后的过程感兴趣则请查看：

-   [Llama 2: 开源并已微调的聊天模型](https://arxiv.org/abs/2307.09288)
-   [Llama 2: 一个超赞的开源大语言模型](https://www.interconnects.ai/p/llama-2-from-meta)
-   [Llama 2: 全面拆解](https://www.youtube.com/watch?v=zJBpRn2zTco&ab_channel=AIExplained)

## LLaMA 2的性能有多好，基准测试？

Meta声称 _"Llama 2在众多外部基准测试中都优于其他开源的语言模型，包括推理、编程、熟练程度与知识测验"_ 关于其性能你可以在这里找到更多信息：

- [Hugging Face 开源大语言模型排行榜](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
- [Meta 官方公告](https://ai.meta.com/llama/)


## 如何提示 LLaMA 2 Chat

LLaMA 2 Chat 是一个开源对话模型。想要与LLaMA 2 Chat进行高效地交互则需要你提供合适的提示词、问题来得到合乎逻辑且有帮助的回复。 Meta并没有选择最简单的提示词结构。以下是单轮、多轮对话的提示词模板。 这个模板遵循模型的训练过程，在此详细描述 [LLaMA 2 论文](https://huggingface.co/papers/2307.09288). 你也可以看一看 [LLaMA 2 提示词模板](https://gpus.llm-utils.org/llama-2-prompt-template/).

单轮对话

```
<s>[INST] <<SYS>>
{{ system_prompt }}
<</SYS>>

{{ user_message }} [/INST]
```

多轮对话

```
<s>[INST] <<SYS>>
{{ system_prompt }}
<</SYS>>

{{ user_msg_1 }} [/INST] {{ model_answer_1 }} </s><s>[INST] {{ user_msg_2 }} [/INST] {{ model_answer_2 }} </s><s>[INST] {{ user_msg_3 }} [/INST]
```

## 如何训练 LLaMA 2

因LLaMA 2为开源模型，使得可以轻易的通过微调技术，比如PEFT，来训练它。这是一些非日适合于训练你自己版本LLaMA 2的学习资源：

-   [扩展指引: 指令微调 Llama 2](https://www.philschmid.de/instruction-tune-llama-2)
-   [在Amazon SageMaker上微调 LLaMA 2 (7-70B)](https://www.philschmid.de/sagemaker-llama2-qlora)
-   [使用PEFT技术微调](https://huggingface.co/blog/llama2#fine-tuning-with-peft)
-   [Meta 提供的Llama模型示例以及方案](https://github.com/facebookresearch/llama-recipes/tree/main)
-   [在本地机器上微调 LLAMA-v2最简单的方法!](https://www.youtube.com/watch?v=3fsn19OI_C8&ab_channel=AbhishekThakur)

## 如何部属 LLaMA 2

LLaMA 2可以在本地环境中部署 ([llama.cpp](https://github.com/ggerganov/llama.cpp))，使用这样已管理好的服务 [Hugging Face Inference Endpoints](https://ui.endpoints.huggingface.co/)或通过AWS, Google Cloud, and Microsoft Azure这样的服务器平台.

-   [使用文本生成接口与推理终端来部署LLama 2](https://huggingface.co/blog/llama2#using-text-generation-inference-and-inference-endpoints)
-   使用 Amazon SageMaker部署LLaMA 2 70B (即将完成)
-   [在你的M1/M2 Mac上通过GPU接口来本地部署Llama-2-13B-chat](https://gist.github.com/adrienbrault/b76631c56c736def9bc1bc2167b5d129)


## 其他资源

-   [Llama 2 资源](https://gpus.llm-utils.org/llama-2-resources/)

如果你想让我再增添一些章节或其他细节请联系我。我致力于提供基于LLaMA 2目前已公开信息的高质量概述。
